{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COSC102 Assignment 3 - Prepared Data\n",
    "The purpose of this notebook is to prepare the data for the model training.\n",
    "We will use the data from the IMU sensor to train a model to predict the activity of the user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Set some lists to store the IMU data.\n",
    "\n",
    "time_track = []\n",
    "ax_set = []\n",
    "ay_set = []\n",
    "az_set = []\n",
    "\n",
    "gx_set = []\n",
    "gy_set = []\n",
    "gz_set = []\n",
    "\n",
    "activity_set = []\n",
    "\n",
    "def map_activity(activity_string):\n",
    "    if activity_string == 'Standing':\n",
    "        return 0\n",
    "    elif activity_string == 'Walking':\n",
    "        return 1\n",
    "    elif activity_string == 'Jogging':\n",
    "        return 2\n",
    "    elif activity_string == 'Side-Step':\n",
    "        return 3\n",
    "    elif activity_string == 'Running':\n",
    "        return 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the IMU data from the csv file.\n",
    "with open ('./datasets/a3_imu_data.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        time_track.append(float(row[0]));\n",
    "        ax_set.append(float(row[1]))\n",
    "        ay_set.append(float(row[2]))\n",
    "        az_set.append(float(row[3]))\n",
    "        gx_set.append(float(row[4]))\n",
    "        gy_set.append(float(row[5]))\n",
    "        gz_set.append(float(row[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the raw IMU data from the csv file.\n",
    "\n",
    "fig, axs = plt.subplots(2,1,figsize=(20,10))\n",
    "axs[0].plot(ax_set, color='r')\n",
    "axs[0].plot(ay_set, color='g')\n",
    "axs[0].plot(az_set, color='b')\n",
    "\n",
    "axs[1].plot(gx_set, color='r')\n",
    "axs[1].plot(gy_set, color='g')\n",
    "axs[1].plot(gz_set, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 800\n",
    "\n",
    "start_ts = time_track[start_idx]\n",
    "print('start_ts: ', start_ts)\n",
    "\n",
    "end_idx = time_track.index(start_ts + 711)\n",
    "\n",
    "# Sanity Check\n",
    "fig, axs = plt.subplots(2,1,figsize=(20,10))\n",
    "axs[0].plot(ax_set[start_idx:end_idx], color='r')\n",
    "axs[0].plot(ay_set[start_idx:end_idx], color='g')\n",
    "axs[0].plot(az_set[start_idx:end_idx], color='b')\n",
    "\n",
    "axs[1].plot(gx_set[start_idx:end_idx], color='r')\n",
    "axs[1].plot(gy_set[start_idx:end_idx], color='g')\n",
    "axs[1].plot(gz_set[start_idx:end_idx], color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add activity annotation to the IMU data from the csv file.\n",
    "with open ('./datasets/a3_activity_annotations.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader, None) # skip the headers\n",
    "    for row in reader:\n",
    "        time_stamp = (row[0].split('='))[1]\n",
    "        activity_set.append([float(time_stamp),row[-1], map_activity(row[-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create an activity time track for each data point within\n",
    "# the imu timeseries. We will have a list to store the numeric code and the string.\n",
    "activity_timeseries = [];\n",
    "activity_string_timeseries = [];\n",
    "activity_idx = 0;\n",
    "\n",
    "# We need the time stamp for the start point\n",
    "start_time = time_track[start_idx]\n",
    "\n",
    "# The time track segment we are interested in \n",
    "time_track_segment = time_track[start_idx:end_idx]\n",
    "\n",
    "# #Add an 'end' activity - this book-ends the data\n",
    "activity_set.append([time_track_segment[-1]-start_time, 'Standing'])\n",
    "\n",
    "# Zero out the time track segment to make it match the video time\n",
    "time_track_segment = np.array(time_track_segment)-start_time\n",
    "\n",
    "ig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(time_track_segment,ax_set[start_idx:end_idx], color='r')\n",
    "ax.plot(time_track_segment,ay_set[start_idx:end_idx], color='g')\n",
    "ax.plot(time_track_segment,az_set[start_idx:end_idx], color='b')\n",
    "\n",
    "\n",
    "for imu_time_track_item in time_track_segment:\n",
    "    current_time =  imu_time_track_item\n",
    "    next_activity_ts = activity_set[activity_idx+1][0]\n",
    "    \n",
    "    # Here we need to move to the next activity in the annotations data if the current\n",
    "    # IMU data point lies after the next annotation time stamp.\n",
    "    if current_time > next_activity_ts:\n",
    "        #Move to nex activity\n",
    "        activity_idx = activity_idx + 1;\n",
    "        next_activity_ts = activity_set[activity_idx+1][0]\n",
    "    \n",
    "    \n",
    "    activity_timeseries.append(activity_set[activity_idx][2])\n",
    "    activity_string_timeseries.append(activity_set[activity_idx][1])\n",
    "\n",
    "# Plot the location of the activity transitions just to sanity check the data\n",
    "for act in np.array(list(zip(*activity_set)))[0,:]:\n",
    "    ax.axvline(float(act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.hist(activity_timeseries, bins=[-0.5,0.5,1.5,2.5,3.5, 4.5] , rwidth=0.5, align='mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are only interested in the video window\n",
    "ax_set = ax_set[start_idx:end_idx]\n",
    "ay_set = ay_set[start_idx:end_idx]\n",
    "az_set = az_set[start_idx:end_idx]\n",
    "gx_set = gx_set[start_idx:end_idx]\n",
    "gy_set = gy_set[start_idx:end_idx]\n",
    "gz_set = gz_set[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can start working on the machine learning workflow.\n",
    "# The first step is to calculate some feature that we can use.\n",
    "# We will base our analysis around a moving window across the\n",
    "# the timeseries data. This involves taking a fixed length window, based upon the time, and\n",
    "# sliding it across the data.\n",
    "# To keep thing simple, we will start with a 1 second window with no overlapping\n",
    "# data points\n",
    "\n",
    "feature_set = []\n",
    "target_set  = []            \n",
    "window_size = 1.0;\n",
    "bad_data_point = [104, 105, 163, 164, 274, 275]            \n",
    "\n",
    "for t in range(int(time_track_segment[0]),int(time_track_segment[-1])):\n",
    "    \n",
    "    #There is a missing data-point (probably due to a bad segment on the SD card)\n",
    "    \n",
    "    if t in bad_data_point:\n",
    "      continue\n",
    "    \n",
    "    #The index function finds the index of the first occurnace of the data\n",
    "    window_start_idx = list(time_track_segment).index(t)\n",
    "    window_end_idx = list(time_track_segment).index(t+window_size)\n",
    "    ax_window = ax_set[window_start_idx:window_end_idx]\n",
    "    ay_window = ay_set[window_start_idx:window_end_idx]\n",
    "    az_window = az_set[window_start_idx:window_end_idx]\n",
    "    gx_window = gx_set[window_start_idx:window_end_idx]\n",
    "    gy_window = gy_set[window_start_idx:window_end_idx]\n",
    "    gz_window = gz_set[window_start_idx:window_end_idx]\n",
    "\n",
    "    #activity that will be assigned to the set of features\n",
    "    activity_code = activity_timeseries[window_start_idx]\n",
    "\n",
    "    # Now we can build features from the data window\n",
    "    # Mean\n",
    "    mu_ax = statistics.mean(ax_window)\n",
    "    mu_ay = statistics.mean(ay_window)\n",
    "    mu_az = statistics.mean(az_window)\n",
    "    mu_gx = statistics.mean(gx_window)\n",
    "    mu_gy = statistics.mean(gy_window)\n",
    "    mu_gz = statistics.mean(gz_window)\n",
    "    \n",
    "    # Max\n",
    "    max_ax = max(ax_window)\n",
    "    max_ay = max(ay_window)\n",
    "    max_az = max(az_window)\n",
    "    max_gx = max(gx_window)\n",
    "    max_gy = max(gy_window)\n",
    "    max_gz = max(gz_window)\n",
    "    \n",
    "    # Min\n",
    "    min_ax = min(ax_window)\n",
    "    min_ay = min(ay_window)\n",
    "    min_az = min(az_window)\n",
    "    min_gx = min(gx_window)\n",
    "    min_gy = min(gy_window)\n",
    "    min_gz = min(gz_window)\n",
    "    \n",
    "    ax_abs_sum = 0\n",
    "    ay_abs_sum = 0\n",
    "    az_abs_sum = 0\n",
    "    \n",
    "    gx_abs_sum = 0\n",
    "    gy_abs_sum = 0\n",
    "    gz_abs_sum = 0\n",
    "    \n",
    "    a_sum_sq = 0\n",
    "    g_sum_sq = 0\n",
    "    \n",
    "    # Here we need to accumulate the values to calculate the SMA and AI\n",
    "    for i in range(0, len(ax_window)):\n",
    "        \n",
    "        # Add up the absolute values for the SMA\n",
    "        ax_abs_sum = ax_abs_sum + abs(ax_window[i])\n",
    "        ay_abs_sum = ay_abs_sum + abs(ay_window[i])\n",
    "        az_abs_sum = az_abs_sum + abs(az_window[i])\n",
    "        \n",
    "        gx_abs_sum = gx_abs_sum + abs(gx_window[i])\n",
    "        gy_abs_sum = gy_abs_sum + abs(gy_window[i])\n",
    "        gz_abs_sum = gz_abs_sum + abs(gz_window[i])\n",
    "        \n",
    "        \n",
    "        a_sum_sq = ((ax_window[i]**2) + (ay_window[i]**2) + (az_window[i]**2)) + a_sum_sq\n",
    "        g_sum_sq = ((gx_window[i]**2) + (gy_window[i]**2) + (gz_window[i]**2)) + g_sum_sq\n",
    "    \n",
    "    # Signal Magnitude area    \n",
    "    a_sma = (ax_abs_sum + ay_abs_sum + az_abs_sum) / len(ax_window)\n",
    "    g_sma = (gx_abs_sum + gy_abs_sum + gz_abs_sum) / len(ax_window)\n",
    "\n",
    "    # Average intensity\n",
    "    a_av_intensity = math.sqrt(a_sum_sq) / len(ax_window)\n",
    "    g_av_intensity = math.sqrt(g_sum_sq) / len(ax_window)\n",
    "\n",
    "\n",
    "    feature_row = [mu_ax, mu_ay, mu_az, mu_gx, mu_gy, mu_gz, \\\n",
    "                   max_ax, max_ay, max_az, max_gx, max_gy, max_gz, \\\n",
    "                   min_ax, min_ay, min_az, min_gx, min_gy, min_gz, \\\n",
    "                   a_sma, g_sma, a_av_intensity, g_av_intensity]\n",
    "\n",
    "    feature_set.append(feature_row)\n",
    "    target_set.append(activity_code)\n",
    "    feature_names = ['mu_ax', 'mu_ay', 'mu_az', 'mu_gx', 'mu_gy', 'mu_gz', \\\n",
    "                    'max_ax', 'max_ay', 'max_az', 'max_gx', 'max_gy', 'max_gz', \\\n",
    "                    'min_ax', 'min_ay', 'min_az', 'min_gx', 'min_gy', 'min_gz', \\\n",
    "                    'a_sma', 'g_sma', 'a_av_intensity', 'g_av_intensity']\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lets visualise some of the features just out of interest - we will look at the SMA and AI\n",
    "plot_range = range(1,705)\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(plot_range,np.array(feature_set)[:,18], color='r')\n",
    "ax.plot(plot_range,np.array(feature_set)[:,19], color='g')\n",
    "ax.plot(plot_range,np.array(feature_set)[:,20], color='b')\n",
    "ax.plot(plot_range,np.array(feature_set)[:,21], color='c')\n",
    "\n",
    "# Plot the location of the activity transitions just to sanity check the data\n",
    "for act in np.array(list(zip(*activity_set)))[0,:]:\n",
    "    ax.axvline(float(act), alpha=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COSC102 Assignment 3 - KNN Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "\n",
    "feature_set = np.array(feature_set)\n",
    "target_set  = np.array(target_set)\n",
    "\n",
    "#Normalisation of data to minimize outliers\n",
    "features_set = preprocessing.MinMaxScaler().fit_transform(feature_set)\n",
    "# Train test split to be fitted            \n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_set, target_set, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## An attempt at optomization for K - kept resulting in 0 (k cannot equal 0) \n",
    "\n",
    "\n",
    "# k_values = [i for i in range (1,31)]\n",
    "# scores = []\n",
    "\n",
    "# for k in k_values:\n",
    "#     knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "#     score = cross_val_score(knn, feature_set, target_set, cv=5)\n",
    "#     scores.append(np.mean(score))\n",
    "    \n",
    "# best_index = np.argmax(scores)\n",
    "# best_k = k_values[best_index]\n",
    "\n",
    "# sns.lineplot(x = k_values, y = scores, marker = 'o')\n",
    "# plt.xlabel(\"K Values\")\n",
    "# plt.ylabel(\"Accuracy Score\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Optimisation of k using accuracy score\n",
    "    # Also includes mean squared error\n",
    "\n",
    "best_k = 0\n",
    "best_mean_f1 = 0\n",
    "f1_set = np.zeros(20)\n",
    "best_k_range = range(3,20) # remove k = 1 and 2 as they are outliers and cause overfitting\n",
    "\n",
    "for k in best_k_range:\n",
    "   #uses p = 1 for distance\n",
    "  clf = neighbors.KNeighborsClassifier(k, weights='uniform', p=1).fit(X_train, y_train)\n",
    "  # Return the predictions for the 5-Fold crossvalidation\n",
    "  y_predicted = cross_val_predict(clf, X_train,y_train, cv=5)\n",
    "\n",
    "  # Print out the recall, precision and F1 scores\n",
    "  print(\"K: \", k)\n",
    "  print(\"F1 Score:\",f1_score(y_train,y_predicted,average=None))\n",
    "  print(\"Accuracy:\",str(accuracy_score(y_train, y_predicted)*100)+\"%\")\n",
    "  print(\"Mean squared error: \",str(np.mean((y_train - y_predicted) ** 2)*100)+\"%\") \n",
    "\n",
    "  # Test\n",
    "  f1_set[k] = np.mean(f1_score(y_train,y_predicted,average=None))\n",
    "  current_f1 = np.mean(f1_score(y_train,y_predicted,average=None))\n",
    "  \n",
    "  if current_f1 > best_mean_f1:\n",
    "    best_mean_f1 = current_f1\n",
    "    best_k = k\n",
    "    best_clf = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best_k_range, f1_set[3:20])\n",
    "plt.xlabel('K')\n",
    "plt.xticks(np.arange(3, 20, 1))\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs K')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot confusion matrices\n",
    "\n",
    "best_clf = neighbors.KNeighborsClassifier(best_k, weights='uniform', p=1).fit(X_train, y_train)\n",
    "\n",
    "# Construct the confusion matricies\n",
    "conf_mat_train = confusion_matrix(y_train, y_predicted)\n",
    "\n",
    "# Plot the confusion matrices\n",
    "fig, ax = plt.subplots()\n",
    "disp = plot_confusion_matrix(best_clf, X_train, y_train,\n",
    "                                 display_labels=['Standing', 'Walking','Jogging', 'Side-Step','Running'],\n",
    "                                 cmap=plt.cm.Blues,ax=ax)\n",
    "# Rotate the labels so they can be read\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "\n",
    "ax.set_title('5-Fold Training - Best K')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "disp = plot_confusion_matrix(best_clf, X_test, y_test,\n",
    "                                 display_labels=['Standing', 'Walking','Jogging', 'Side-Step','Running'],\n",
    "                                 cmap=plt.cm.Blues,ax=ax)\n",
    "# Rotate the labels so they can be read\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "\n",
    "ax.set_title('Testing Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ROC and AUC for each class\n",
    "y_score = best_clf.predict_proba(X_test)\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3, 4])\n",
    "n_classes = y_test_bin.shape[1]\n",
    "class_names = ['Standing', 'Walking','Jogging', 'Side-Step','Running']\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot the ROC curves\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for class %s' % (roc_auc[i], class_names[i]))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.set_title('Receiver operating characteristic for KNN')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 2 x Visuals of KNN with test data\n",
    "#Uses \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, neighbors\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "#list of features names\n",
    "f_names = [\"Mean Ax\", \"Mean Ay\", \"Mean Az\",\"Mean Gx\", \"Mean Gy\", \"Mean Gz\",\n",
    "           \"Max Ax\", \"Max Ay\", \"Max Az\",\"Max Gx\", \"Max Gy\", \"Max Gz\", \n",
    "           \"Min Ax\", \"Min Ay\", \"Min Az\",\"Min Gx\", \"Min Gy\", \"Min Gz\",\n",
    "           \"Acceleration SMA\", \"Gyroscope SMA\" , \"Acceleration AI\", \"Gyroscope AI\"]\n",
    "\n",
    "\n",
    "#plot Acceleration AI vs Gyroscope AI\n",
    "X = X_test[:,20:22]\n",
    "y = y_test\n",
    "\n",
    "viz_clf = neighbors.KNeighborsClassifier(best_k, weights='uniform', p=1).fit(X, y)\n",
    "\n",
    "h = 50\n",
    "cmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue', 'red', 'lightseagreen'])\n",
    "cmap_bold = ListedColormap(['darkorange', 'c', 'darkblue', 'darkred', 'g'])\n",
    " \n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    " \n",
    "Z = viz_clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"kNN classification (k = %i)\" % best_k)\n",
    "plt.xlabel(f_names[20])\n",
    "plt.ylabel(f_names[21])\n",
    "plt.show()\n",
    "\n",
    "#plot Acceleration SMA vs Gyroscpoce SMA\n",
    "X = X_test[:,18:20]\n",
    "y = y_test\n",
    "\n",
    "viz_clf = neighbors.KNeighborsClassifier(best_k, weights='uniform', p=1).fit(X, y)\n",
    "\n",
    "h = 50\n",
    "cmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue', 'red', 'lightseagreen'])\n",
    "cmap_bold = ListedColormap(['darkorange', 'c', 'darkblue', 'darkred', 'g'])\n",
    " \n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    " \n",
    "Z = viz_clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"kNN classification (k = %i)\" % best_k)\n",
    "plt.xlabel(f_names[18])\n",
    "plt.ylabel(f_names[19])\n",
    "plt.show()\n",
    "\n",
    "#For video: shows that those features are not the best but there is decisionn boundaries. \n",
    "#When using a higher k (10) it is not as precise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
