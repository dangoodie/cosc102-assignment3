{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5 - Activity Recognition\n",
    "\n",
    "Make sure that you review the video introduction for this tutorial. Otherwise it will not make sense!\n",
    "\n",
    "In this tutorial we are going to reviewing a complete workflow that ties together data colection, data annotation and training of a machine learning algorithm on a small dataset collected using an Inertial Measurement Unit(IMU). The IMU used to create the dataset is the SparkFun 9DoF Razor IMU: https://www.sparkfun.com/products/14001 \n",
    "\n",
    "This device has been programmed to store the readings from the on-board accelerometer and gyroscope to a file on the SD card at (approximately) 250 samples per second. A video of the data collection was recorded and used to create an *annotation* dataset that contains time-stamped annotations of activities.\n",
    "\n",
    "The first part of this demonstration involves importing the IMU data and aligning it with the video and annotation data. This is done by inspecting the dataset to look for *sentinel* sections or known *datum* points between both sets. In this example, we will be using the standing points to synchonize the datasets. \n",
    "\n",
    "We will start by setting things up for the data import.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all of the \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import dtreeviz\n",
    "\n",
    "# Set some lists to store the IMU data.\n",
    "\n",
    "time_track = []\n",
    "ax_set = []\n",
    "ay_set = []\n",
    "az_set = []\n",
    "\n",
    "gx_set = []\n",
    "gy_set = []\n",
    "gz_set = []\n",
    "\n",
    "activity_set = []\n",
    "\n",
    "#####################################################\n",
    "# map_activity(activity_string)\n",
    "#\n",
    "# A simple function that maps the activity description\n",
    "# string from the VoTT data file to a integer value\n",
    "# that will be used by the machine learning workflow.\n",
    "#\n",
    "#####################################################\n",
    "\n",
    "def map_activity(activity_string):\n",
    "    if activity_string == 'Standing':\n",
    "        return 0\n",
    "    elif activity_string == 'Walking':\n",
    "        return 1\n",
    "    elif activity_string == 'Jogging':\n",
    "        return 2\n",
    "    elif activity_string == 'Side_step':\n",
    "        return 3\n",
    "    elif activity_string == 'Running':\n",
    "        return 4\n",
    "    elif activity_string == 'High_knees':\n",
    "        return 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import the data file colelcted from the IMU. We will store the data in a set of lists for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outfile.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        #print(row)\n",
    "        time_track.append(float(row[0]));\n",
    "        ax_set.append(float(row[1]));\n",
    "        ay_set.append(float(row[2]));\n",
    "        az_set.append(float(row[3]));\n",
    "        gx_set.append(float(row[4]));\n",
    "        gy_set.append(float(row[5]));\n",
    "        gz_set.append(float(row[6]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we will do is visualise the data to sanity check what we have imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,figsize=(20,10))\n",
    "axs[0].plot(ax_set, color='r')\n",
    "axs[0].plot(ay_set, color='g')\n",
    "axs[0].plot(az_set, color='b')\n",
    "\n",
    "axs[1].plot(gx_set, color='r')\n",
    "axs[1].plot(gy_set, color='g')\n",
    "axs[1].plot(gz_set, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection, we can see that the data we are after is @ approx. position 250000-360000. By experimentation and a review of the accompanying video, we can observe that the data we are after starts at index 262000. This closly corresponds with the start of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 262000\n",
    "\n",
    "fig, axs = plt.subplots(2,1,figsize=(20,10))\n",
    "axs[0].plot(ax_set[start_idx:370000], color='r')\n",
    "axs[0].plot(ay_set[start_idx:370000], color='g')\n",
    "axs[0].plot(az_set[start_idx:370000], color='b')\n",
    "\n",
    "axs[1].plot(gx_set[start_idx:370000], color='r')\n",
    "axs[1].plot(gy_set[start_idx:370000], color='g')\n",
    "axs[1].plot(gz_set[start_idx:370000], color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the start point. Now we need to find the end point in the data. This is conveniently given by the length of the data collection video (443 seconds). This video has been 'cut' using editing software so that the start and end of the video matches the start and end of the activities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to find the end point\n",
    "start_ts = time_track[start_idx];\n",
    "print(start_ts)\n",
    "\n",
    "# The video has been cut to 443 seconds in length - need to find \n",
    "# Start_ts + 443 seconds. This should land us at the end point\n",
    "# We can sanity check this by inspecting the plot\n",
    "\n",
    "end_idx = time_track.index(start_ts+443)\n",
    "\n",
    "# Sanity Check\n",
    "fig, axs = plt.subplots(2,1,figsize=(20,10))\n",
    "axs[0].plot(ax_set[start_idx:end_idx], color='r')\n",
    "axs[0].plot(ay_set[start_idx:end_idx], color='g')\n",
    "axs[0].plot(az_set[start_idx:end_idx], color='b')\n",
    "\n",
    "axs[1].plot(gx_set[start_idx:end_idx], color='r')\n",
    "axs[1].plot(gy_set[start_idx:end_idx], color='g')\n",
    "axs[1].plot(gz_set[start_idx:end_idx], color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The Activity Annotations\n",
    "\n",
    "Now we can turn our attention to the activity track that we have created using VoTT. First we need to read in the activity annotation file that we made in VoTT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imu_data-export.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader, None)  # skip the headers\n",
    "    for row in reader:\n",
    "        time_Stamp = (row[0].split('='))[1]\n",
    "        activity_set.append([float(time_Stamp),row[-1], map_activity(row[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the activity annotations from the VoTT file, the first task is to assign every data reading within the IMU dataset a corresponding activity. The annoations file simply lists the start time for each activity - we needed to use these time listings to assign an activity to each data point using the timestamp within the IMU dataset.\n",
    "\n",
    "You can download and explort VoTT from the website: https://github.com/microsoft/VoTT\n",
    "\n",
    "We will achieve this by looping through the IMU data and assigning the corresponding activity from the activity annotation file. We start at the first activity annoation and the first IMU data point.\n",
    "\n",
    "We will also plot the annotation points (as vertical lines) to sanity check the activity transitions and see if they correspond to changes in the underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create an activity time track for each data point within\n",
    "# the imu timeseries. We will have a list to store the numeric code and the string.\n",
    "activity_timeseries = [];\n",
    "activity_string_timeseries = [];\n",
    "activity_idx = 0;\n",
    "\n",
    "# We need the time stamp for the start point\n",
    "start_time = time_track[start_idx]\n",
    "\n",
    "# The time track segment we are interested in \n",
    "time_track_segment = time_track[start_idx:end_idx]\n",
    "\n",
    "#Add an 'end' activity - this book-ends the data\n",
    "activity_set.append([time_track_segment[-1]-start_time, 'Standing'])\n",
    "\n",
    "# Zero out the time track segment to make it match the video time\n",
    "time_track_segment = np.array(time_track_segment)-start_time\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(time_track_segment,ax_set[start_idx:end_idx], color='r')\n",
    "ax.plot(time_track_segment,ay_set[start_idx:end_idx], color='g')\n",
    "ax.plot(time_track_segment,az_set[start_idx:end_idx], color='b')\n",
    "\n",
    "\n",
    "for imu_time_track_item in time_track_segment:\n",
    "    current_time =  imu_time_track_item\n",
    "    next_activity_ts = activity_set[activity_idx+1][0]\n",
    "    \n",
    "    # Here we need to move to the next activity in the annotations data if the current\n",
    "    # IMU data point lies after the next annotation time stamp.\n",
    "    if current_time > next_activity_ts:\n",
    "        #Move to nex activity\n",
    "        activity_idx = activity_idx + 1;\n",
    "        next_activity_ts = activity_set[activity_idx+1][0]\n",
    "    \n",
    "    \n",
    "    activity_timeseries.append(activity_set[activity_idx][2])\n",
    "    activity_string_timeseries.append(activity_set[activity_idx][1])\n",
    "\n",
    "# Plot the location of the activity transitions just to sanity check the data\n",
    "for act in np.array(list(zip(*activity_set)))[0,:]:\n",
    "    ax.axvline(float(act))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be good to understand the balance of the data classes (i.e. the number of data points for each activity). This will inform us around the expected performance in a classifier algorithm. We will plot a histgram using the numeric activity code data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.hist(activity_timeseries,bins=[-0.5,0.5,1.5,2.5,3.5,4.5,5.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are only interested in the video window\n",
    "ax_set = ax_set[start_idx:end_idx]\n",
    "ay_set = ay_set[start_idx:end_idx]\n",
    "az_set = az_set[start_idx:end_idx]\n",
    "gx_set = gx_set[start_idx:end_idx]\n",
    "gy_set = gy_set[start_idx:end_idx]\n",
    "gz_set = gz_set[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Features\n",
    "\n",
    "Now we have a combined dataset, we can start looking at applying a machine learning workflow. The first part of this process will involve computing some features for the dataset. \n",
    "\n",
    "To make our data generalize, we are interesting in look at at *windows* of data - small segments that correspond to specific time periods within the data. This is called the 'moving' window approach and it essentially involves taking fixed-length segments of data and calculating *features* across these segments. We will compute features across the accelerometer and gyroscope datasets.\n",
    "\n",
    "The features we will calculate are:\n",
    "* Mean (x, y and z axes)\n",
    "* Minimum (x, y and z axes)\n",
    "* Maximum (x, y and z axes)\n",
    "* The Signal Magnitude Area: $ SMA = \\frac{1}{T} (\\sum _{t=1}^{T} |{a_x(t)}| + \\sum _{t=1}^{T} |{a_y(t)}| + (\\sum _{t=1}^{T} |{a_z(t)}|)$\n",
    "\n",
    "* Average intensity $ AI = \\frac{1}{T} (\\sum _{t=1}^{T} (\\sqrt{a_x(t)^2 + a_y(t)^2 + a_y(t)^2})$\n",
    "\n",
    "These features are based upon experiments and literature and have proven effective for activity classification across a range of applications.\n",
    "\n",
    "Will will use a **window size of 1 second**. This is a parameter that we can adjust and experiment with, however in previous experiments on human acticity, a 1 second window has been very effective. \n",
    "\n",
    "This code takes a few seconds to run - there are a lot of calculations!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can start working on the machine learning workflow.\n",
    "# The first step is to calculate some feature that we can use.\n",
    "# We will base our analysis around a moving window across the\n",
    "# the timeseries data. This involves taking a fixed length window, based upon the time, and\n",
    "# sliding it across the data.\n",
    "# To keep thing simple, we will start with a 1 second window with no overlapping\n",
    "# data points\n",
    "\n",
    "feature_set = []\n",
    "target_set  = []            \n",
    "window_size = 1.0;            \n",
    "\n",
    "for t in range(int(time_track_segment[0]),int(time_track_segment[-1])):\n",
    "    \n",
    "    #There is a missing data-point (probably due to a bad segment on the SD card)\n",
    "    if t == 60 or t == 61 :\n",
    "        continue\n",
    "    \n",
    "    #The index function finds the index of the first occurnace of the data\n",
    "    window_start_idx = list(time_track_segment).index(t)\n",
    "    window_end_idx = list(time_track_segment).index(t+window_size)\n",
    "    ax_window = ax_set[window_start_idx:window_end_idx]\n",
    "    ay_window = ay_set[window_start_idx:window_end_idx]\n",
    "    az_window = az_set[window_start_idx:window_end_idx]\n",
    "    gx_window = gx_set[window_start_idx:window_end_idx]\n",
    "    gy_window = gy_set[window_start_idx:window_end_idx]\n",
    "    gz_window = gz_set[window_start_idx:window_end_idx]\n",
    "\n",
    "    #activity that will be assigned to the set of features\n",
    "    activity_code = activity_timeseries[window_start_idx]\n",
    "\n",
    "    # Now we can build features from the data window\n",
    "    # Mean\n",
    "    mu_ax = statistics.mean(ax_window)\n",
    "    mu_ay = statistics.mean(ay_window)\n",
    "    mu_az = statistics.mean(az_window)\n",
    "    mu_gx = statistics.mean(gx_window)\n",
    "    mu_gy = statistics.mean(gy_window)\n",
    "    mu_gz = statistics.mean(gz_window)\n",
    "    \n",
    "    # Max\n",
    "    max_ax = max(ax_window)\n",
    "    max_ay = max(ay_window)\n",
    "    max_az = max(az_window)\n",
    "    max_gx = max(gx_window)\n",
    "    max_gy = max(gy_window)\n",
    "    max_gz = max(gz_window)\n",
    "    \n",
    "    # Min\n",
    "    min_ax = min(ax_window)\n",
    "    min_ay = min(ay_window)\n",
    "    min_az = min(az_window)\n",
    "    min_gx = min(gx_window)\n",
    "    min_gy = min(gy_window)\n",
    "    min_gz = min(gz_window)\n",
    "    \n",
    "    ax_abs_sum = 0\n",
    "    ay_abs_sum = 0\n",
    "    az_abs_sum = 0\n",
    "    \n",
    "    gx_abs_sum = 0\n",
    "    gy_abs_sum = 0\n",
    "    gz_abs_sum = 0\n",
    "    \n",
    "    a_sum_sq = 0\n",
    "    g_sum_sq = 0\n",
    "    \n",
    "    # Here we need to accumulate the values to calculate the SMA and AI\n",
    "    for i in range(0, len(ax_window)):\n",
    "        \n",
    "        # Add up the absolute values for the SMA\n",
    "        ax_abs_sum = ax_abs_sum + abs(ax_window[i])\n",
    "        ay_abs_sum = ay_abs_sum + abs(ay_window[i])\n",
    "        az_abs_sum = az_abs_sum + abs(az_window[i])\n",
    "        \n",
    "        gx_abs_sum = gx_abs_sum + abs(gx_window[i])\n",
    "        gy_abs_sum = gy_abs_sum + abs(gy_window[i])\n",
    "        gz_abs_sum = gz_abs_sum + abs(gz_window[i])\n",
    "        \n",
    "        \n",
    "        a_sum_sq = ((ax_window[i]**2) + (ay_window[i]**2) + (az_window[i]**2)) + a_sum_sq\n",
    "        g_sum_sq = ((gx_window[i]**2) + (gy_window[i]**2) + (gz_window[i]**2)) + g_sum_sq\n",
    "    \n",
    "    # Signal Magnitude area    \n",
    "    a_sma = (ax_abs_sum + ay_abs_sum + az_abs_sum) / len(ax_window)\n",
    "    g_sma = (gx_abs_sum + gy_abs_sum + gz_abs_sum) / len(ax_window)\n",
    "\n",
    "    # Average intensity\n",
    "    a_av_intensity = math.sqrt(a_sum_sq) / len(ax_window)\n",
    "    g_av_intensity = math.sqrt(g_sum_sq) / len(ax_window)\n",
    "\n",
    "\n",
    "    feature_row = [mu_ax, mu_ay, mu_az, mu_gx, mu_gy, mu_gz, \\\n",
    "                   max_ax, max_ay, max_az, max_gx, max_gy, max_gz, \\\n",
    "                   min_ax, min_ay, min_az, min_gx, min_gy, min_gz, \\\n",
    "                   a_sma, g_sma, a_av_intensity, g_av_intensity]\n",
    "\n",
    "    feature_set.append(feature_row)\n",
    "    target_set.append(activity_code)\n",
    "\n",
    "# Lets visualise some of the features just out of interest - we will look at the SMA and AI\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax.plot(range(1,441),np.array(feature_set)[:,18], color='r')\n",
    "ax.plot(range(1,441),np.array(feature_set)[:,19], color='g')\n",
    "ax.plot(range(1,441),np.array(feature_set)[:,20], color='b')\n",
    "ax.plot(range(1,441),np.array(feature_set)[:,21], color='c')\n",
    "\n",
    "# Plot the location of the activity transitions just to sanity check the data\n",
    "for act in np.array(list(zip(*activity_set)))[0,:]:\n",
    "    ax.axvline(float(act), alpha=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a Machine Learning Classifier\n",
    "\n",
    "Now we have a dataset with features and targets. We can apply a machine leanring algorithm. We will train a decision tree algorithms using our usually workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "# Now we can apply a classifier - we will use a simple Decision Tree classifier for this demo.            \n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_set, target_set)\n",
    "# Set the number neightbours to use in the classifier\n",
    "#n_neighbors = 10\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "#clf = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')\n",
    "\n",
    "# Train\n",
    "clf = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "# Return the predictions for the 3-Fold crossvalidation\n",
    "y_predicted = cross_val_predict(clf, X_train,y_train, cv=3)\n",
    "# Return the predictions for the test set\n",
    "y_test_predicted = clf.predict(X_test)\n",
    "# Construct the confusion matricies\n",
    "conf_mat_train = confusion_matrix(y_train, y_predicted)\n",
    "conf_mat_test = confusion_matrix(y_test, y_test_predicted)\n",
    "\n",
    "# Print out the recall, precision and F1 scores\n",
    "# There will be a value for each class\n",
    "# CV Train\n",
    "print(\"CV Train Recall:\", recall_score(y_train,y_predicted,average=None))\n",
    "print(\"CV Train Precision:\",precision_score(y_train,y_predicted,average=None))\n",
    "print(\"CV Train F1 Score:\",f1_score(y_train,y_predicted,average=None))\n",
    "\n",
    "# Test\n",
    "print(\"Test Recall:\",recall_score(y_test,y_test_predicted,average=None))\n",
    "print(\"Test Precision:\",precision_score(y_test,y_test_predicted,average=None))\n",
    "print(\"Test F1 Score:\",f1_score(y_test,y_test_predicted,average=None))\n",
    "\n",
    "# Plot the confusion matrices using the pretty functions\n",
    "fig, ax = plt.subplots()\n",
    "disp = plot_confusion_matrix(clf, X_train, y_train,\n",
    "                                 display_labels=['Standing', 'Walking','Jogging', 'Side Step','Running','High Knees'],\n",
    "                                 cmap=plt.cm.Blues,ax=ax)\n",
    "# Rotate the labels so they can be read\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "\n",
    "ax.set_title('3-Fold Training')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                                 display_labels=['Standing', 'Walking','Jogging', 'Side Step','Running','High Knees'],\n",
    "                                 cmap=plt.cm.Blues,ax=ax)\n",
    "# Rotate the labels so they can be read\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names - I used a dictionary structure because the dtreeviz module was playing up with a list\n",
    "c_names = {0:\"Standing\", 1:\"Walking\", 2:\"Jogging\", 3:\"Side-Step\", 4:\"Running\", 5:\"High-Knees\"}\n",
    "# Feature names for the tree.\n",
    "f_names = [\"Mean Ax\", \"Mean Ay\", \"Mean Az\",\"Mean Gx\", \"Mean Gy\", \"Mean Gz\",\n",
    "           \"Max Ax\", \"Max Ay\", \"Max Az\",\"Max Gx\", \"Max Gy\", \"Max Gz\", \n",
    "           \"Min Ax\", \"Min Ay\", \"Min Az\",\"Min Gx\", \"Min Gy\", \"Min Gz\",\n",
    "           \"Acceleration SMA\", \"Gyroscope SMA\" , \"Acceleration AI\", \"Gyroscope AI\"]\n",
    "\n",
    "# Visualise the best classifier using dtreeviz\n",
    "viz = dtreeviz.model(clf, \n",
    "     np.array(X_train), \n",
    "     np.array(y_train),\n",
    "     target_name ='Outcome',\n",
    "     feature_names = f_names,\n",
    "     class_names = c_names\n",
    "    )  \n",
    "              \n",
    "viz.view() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises for You\n",
    "\n",
    "This tutorial is primerily a demonstration of the *data collection-to-machine leaning* workflow, however there a  few simple tasks to help you explore the code.\n",
    "\n",
    "1. Modify the code above and explore the impact of changing the `max_depth` of the decision tree.\n",
    "2. From observation of the tree visualisation, which features appear to be the most important for the classifiction?\n",
    "3. What issues can you identify with the dataset and how are these expressed in the results?\n",
    "4. Modify the code to train a KNN neighbours classifier and assess its performance (explore the N hyperparameter and see what effect it has on the classification).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 10\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = cross_val_predict(clf, X_train,y_train, cv=3)\n",
    "y_test_predicted = clf.predict(X_test)\n",
    "conf_mat_train = confusion_matrix(y_train, y_predicted)\n",
    "conf_mat_test = confusion_matrix(y_test, y_test_predicted)\n",
    "\n",
    "print(\"CV Train Recall:\", recall_score(y_train,y_predicted,average=None))\n",
    "print(\"CV Train Precision:\",precision_score(y_train,y_predicted,average=None))\n",
    "print(\"CV Train F1 Score:\",f1_score(y_train,y_predicted,average=None))\n",
    "\n",
    "print(\"Test Recall:\",recall_score(y_test,y_test_predicted,average=None))\n",
    "print(\"Test Precision:\",precision_score(y_test,y_test_predicted,average=None))\n",
    "print(\"Test F1 Score:\",f1_score(y_test,y_test_predicted,average=None))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "disp = plot_confusion_matrix(clf, X_train, y_train,\n",
    "                                 display_labels=['Standing', 'Walking','Jogging', 'Side Step','Running','High Knees'],\n",
    "                                 cmap=plt.cm.Blues,ax=ax)\n",
    "# Rotate the labels so they can be read\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "\n",
    "ax.set_title('3-Fold Training')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                                 display_labels=['Standing', 'Walking','Jogging', 'Side Step','Running','High Knees'],\n",
    "                                 cmap=plt.cm.Blues,ax=ax)\n",
    "# Rotate the labels so they can be read\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
